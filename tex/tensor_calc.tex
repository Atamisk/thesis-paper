\section{The Reliability Index}
\label{sec:beta}
The reliability index is a unitless constant that can be used to infer the probability of a system or component to fail in service. Roughly, the Reliability index describes the safety factor of a system as the Z-score of a standard normal distribution, where higher numbers indicate higher probabilities of success. The Reliability Index of a loading condition can be written as: 
   \begin{equation}
	   \beta = \frac{\mu_{Sy} - \mu_\sigma}{\sqrt{\sigma_{\sigma}^2 + \sigma_{Sy}^2}}
	   \label{eq:beta}
   \end{equation}
Where
   \begin{align*}
	   \mu_{Sy} &= \text{Mean of the material yielding stress}\\
	   \sigma_{Sy} &= \text{Std. Deviation of the yielding stress}\\
	   \mu_{\sigma} &= \text{Mean of the Von Mises stress resulting from the applied load}\\
	   \sigma_{\sigma} &= \text{Std. Deviation of the Von Mises stress resulting from the applied load}
   \end{align*}

The first two variables in the list above relate to properties of the material the object is made from, and are therefore given or assumed. The second two, however, relate to the von Mises stress and must be calculated.

\subsection{Finding $\mu_\sigma$ and $\sigma_\sigma$}
If $g(x_1, x_2, ... x_n) = Y$ denotes a function of multiple random variates and a single, dependent variable, let:\todo{cite} 
   \begin{align}
	   \mu(Y) = g(x_1, x_2, ... x_n) + \frac{1}{2} \sum_{i=1}^{n}\left( \frac{\partial^2 g}{\partial x_i^2} \sigma_{xi}^2  \right)
	            \label{eq:mu}\\
	   \sigma^2(Y) = \sum_{i=1}^{n}\left( \frac{\partial g}{\partial x_i} \sigma_{xi}  \right)^2 + 
			 \frac{1}{4} \sum_{i=1}^{n}\left( \frac{\partial^2 g}{\partial x_i^2} \sigma_{xi}^2  \right)^2 \label{eq:sigma}
   \end{align}
The tensor definition of the von Mises stress at a given location can be written as:
   \begin{equation}
      \sigma = \sqrt{\frac{3}{2} \cdot \left(\sigma_{dev}:\sigma_{dev} \right)}
	\label{eq:basedef}
   \end{equation}
Where $\sigma_{dev}$ is the stress deviator tensor, which will be more completely addressed later. 
We can simplify derivation of equation \ref{eq:basedef} by hiding the tensor contraction in the equation with a placeholder variable:
   \begin{align}
	   \alpha = (\sigma_{dev}:\sigma_{dev})
	   \label{eq:defalpha}
   \end{align}
This turns equation \ref{eq:basedef} into:
   \begin{align}
      \sigma' = \sqrt{\frac{3}{2} \cdot \left(\alpha\right)}
   \end{align}
This simplified equation can be derived as shown below: 
   \begin{align}
	   \frac{\partial \sigma'}{\partial P_x} &= \frac{3}{4} \frac{\partial \alpha}{\partial P_x} 
						    \left( \frac{3}{2} \alpha \right)^{-\frac{1}{2}}\label{eq:fd_vmx}\\
	   \frac{\partial^2 \sigma'}{\partial P_x^2} &= \frac{3}{4} \frac{\partial ^2 \alpha}{\partial P_x^2}
	                                                \left( \frac{3}{2} \alpha \right)^{-\frac{1}{2}} - 
							\frac{9}{16} \left(\frac{\partial \alpha}{\partial P_x}\right)^2
							\left( \frac{3}{2} \alpha \right)^{-\frac{3}{2}}\\
	   \frac{\partial \sigma'}{\partial P_y} &= \frac{3}{4} \frac{\partial \alpha}{\partial P_y} 
	                                            \left( \frac{3}{2} \alpha \right)^{-\frac{1}{2}}\\
	   \frac{\partial^2 \sigma'}{\partial P_y^2} &= \frac{3}{4} \frac{\partial ^2 \alpha}{\partial P_y^2}
	                                                \left( \frac{3}{2} \alpha \right)^{-\frac{1}{2}} - 
							\frac{9}{16} \left(\frac{\partial \alpha}{\partial P_y}\right)^2
							\left( \frac{3}{2} \alpha \right)^{-\frac{3}{2}}\label{eq:sd_vmy}
   \end{align}
Of course, this introduces derivatives of $\alpha$ as values that must be calculated. In order to calculate these derivatives, the concept and application of the deviator tensor must be investigated further.


The Deviatoric Stress Tensor (or deviator tensor) describes the component of stress that tends to deform an element. It is given in terms of the overall stress tensor $\sigma'$ as: 
   \begin{equation}
      \sigma_{dev} = \sigma' - \frac{1}{3} \mathrm{tr}(\sigma') \left[ \mathbf{I} \right]
   \end{equation}
For purposes that will become clear later, we can call this operation a matrix operator $\gamma$:
   \begin{align}
      \gamma(x) &= x - \frac{1}{3} \mathrm{tr}(x) \left[ \mathbf{I} \right]\label{eq:gamma}\\
      \sigma_{dev} &= \gamma(\sigma') \nonumber
   \end{align}
In this study, $\sigma'$ is constructed from the component response tensors, $\sigma_{Px}$ and $\sigma_{Py}$\todo{Explain earlier in the paper how these values come to be.}:
   \begin{equation*}
      \sigma' = \sigma_{Px} \cdot P_x + \sigma_{Py} \cdot P_y
   \end{equation*}
Applying equation \ref{eq:gamma} to the above definition of $\sigma'$ yields:
   \begin{align}
	   \gamma_(\sigma') &= \left(\sigma_{Px} \cdot P_x + \sigma_{Py} \cdot P_y\right) - 
                       \frac{1}{3} \mathrm{tr} \left(\sigma_{Px} \cdot P_x + \sigma_{Py}
                       \cdot P_y\right) \left[ \mathbf{I} \right] 
   \end{align}
From here, it is important to remember that taking the trace of a matrix is a distributive operation, as is multiplying a scalar and a matrix. Therefore, the above equation can be rewritten as: 
   \begin{align}
	   \gamma(\sigma') &= \left(\sigma_{Px} \cdot P_x + \sigma_{Py} \cdot P_y\right) - 
                       \frac{1}{3} \left(\mathrm{tr} \left(\sigma_{Px} \cdot P_x\right) +
                       \mathrm{tr} \left( \sigma_{Py} \cdot P_y\right)\right) 
                       \left[ \mathbf{I} \right]\nonumber \\
                      &= \left(\sigma_{Px} \cdot P_x + \sigma_{Py} \cdot P_y\right) - 
		       \frac{1}{3} \left(\mathrm{tr} \left(\sigma_{Px} \cdot P_x\right)
		       \left[ \mathbf{I} \right] +
                       \mathrm{tr} \left( \sigma_{Py} \cdot P_y\right) 
                       \left[ \mathbf{I} \right]\right)\nonumber\\
		      &= \left(\sigma_{Px} \cdot P_x + \sigma_{Py} \cdot P_y\right) - 
		       \frac{1}{3} \left(P_x \cdot \mathrm{tr} \left(\sigma_{Px}\right)
		       \left[ \mathbf{I} \right] +
                       P_y \cdot \mathrm{tr} \left( \sigma_{Py} \right) 
                       \left[ \mathbf{I} \right]\right)\nonumber\\
		      &= P_x \cdot \left( \sigma_{Px} - \frac{1}{3} \mathrm{tr}(\sigma_{Px})
			 \left[ \mathbf{I} \right] \right) + P_y \cdot \left( \sigma_{Py} -
			 \frac{1}{3} \mathrm{tr}(\sigma_{Py})
			 \left[ \mathbf{I} \right] \right)\nonumber\\
		      &= P_x \cdot \gamma(\sigma_{Px}) + P_y \cdot \gamma(\sigma_{Py})
   \end{align}
Note that the terms $\gamma(\sigma_{Px})$ and $\gamma(\sigma_{Py})$ do not contain any terms related to $P_x$ or $P_y$. This implies that they are constant when deriving with respect to these variables. From this point forward, we will refer to these deviatoric unit tensors as:

   \begin{align*}
	   \gamma(\sigma_{Px}) &= \sigma_{devx}\\
	   \gamma(\sigma_{Py}) &= \sigma_{devy}
   \end{align*}
This means: 
   \begin{equation}
	   \sigma_{dev} = \sigma_{devx} \cdot P_x + \sigma_{devy} \cdot P_y
   \end{equation}

Returning to equation \ref{eq:defalpha}, we can begin to define $\alpha$ in terms of these new tensors. To start with, we need to breakdown the ``:" operator in the equation. This is the tensor contraction operator, and is defined as: 
   \begin{equation}
	   \left[A\right] : \left[B\right] = \mathrm{tr}(\left[A\right]\left[B\right])
	   \label{eq:tensorcont}
   \end{equation}
Because both matrix multiplication and the trace of a matrix are both distributive, the tensor contraction operator is also distributive. Using the definition in \ref{eq:tensorcont} and applying it to \ref{eq:defalpha} yields: 
   \begin{align}
	   \alpha &= \mathrm{tr}\left[(\sigma_{devx} \cdot P_x + \sigma_{devy} \cdot P_y) \cdot
		    (\sigma_{devx} \cdot P_x + \sigma_{devy} \cdot P_y)\right]\nonumber\\
		  &= \mathrm{tr}\left[\sigma_{devx} \cdot \sigma_{devx} \cdot P_x^2 + \left( 
		     \sigma_{devx} \cdot \sigma_{devy} + \sigma_{devy} \cdot \sigma_{devx} \right) \cdot P_x P_y + 
		     \sigma_{devy} \cdot \sigma_{devy} \cdot P_y^2 \right]
   \end{align}
Note that the center term is arranged as shown due to the non-commutative nature of matrix multiplication.
Now, we can take this definition of $\alpha$ and easily find the derivatives we need.
   \begin{align}
	   \frac{\partial \alpha}{\partial P_x} &= 
	   	\mathrm{tr}\left[\sigma_{devx} \cdot \sigma_{devx} \cdot 2P_x + \left( 
		     \sigma_{devx} \cdot \sigma_{devy} + \sigma_{devy} \cdot \sigma_{devx} \right) \cdot P_y \right]\label{eq:fd_ax}\\
	   \frac{\partial^2 \alpha}{\partial P_x^2} &=
	   	\mathrm{tr}\left[2 \cdot \sigma_{devx} \cdot \sigma_{devx} \right]\\
	   \frac{\partial \alpha}{\partial P_y} &= 
	   	\mathrm{tr}\left[\sigma_{devy} \cdot \sigma_{devy} \cdot 2P_y + \left( 
		     \sigma_{devx} \cdot \sigma_{devy} + \sigma_{devy} \cdot \sigma_{devx} \right) \cdot P_x \right]\\
	   \frac{\partial^2 \alpha}{\partial P_x^2} &=
		\mathrm{tr}\left[2 \cdot \sigma_{devy} \cdot \sigma_{devy} \right]\label{eq:sd_ay}
   \end{align}

   With equations \ref{eq:fd_ax} through \ref{eq:sd_ay} coupled with equations \ref{eq:fd_vmx} through \ref{eq:sd_vmy}, we have all of the terms needed to construct and solve equations \ref{eq:mu} and \ref{eq:sigma} for $\sigma$. It is then easy to substitute the results of equations \ref{eq:mu} and \ref{eq:sigma} into \ref{eq:beta} and determine $\beta$.  In the code presented with this report, all of these terms are assembled separately and combined. Therefore, the final equation with all substitutions performed will not be shown here.

